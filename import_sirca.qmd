---
title: "Importing SIRCA ASX EOD data"
author: Ian D. Gow
date: 2024-06-29
date-format: "D MMMM YYYY"
format:
  html:
    colorlinks: true
  pdf:
    colorlinks: true
    geometry:
    - left=2.5cm
    - right=2.5cm
    papersize: a4
    mainfont: TeX Gyre Pagella
    mathfont: TeX Gyre Pagella Math
bibliography: papers.bib
---

Two levels:

1. Importing the specific data sets comprised by the SIRCA ASX EOD library.
2. Illustrating general principles for importing data using the SIRCA ASX EOD library as a case study.

What are these principles?

1. 

In writing this note, I use the packages listed below, plus the `duckdb` package.^[Execute `install.packages(c("tidyverse", "DBI", "duckdb", "arrow", "farr", "janitor"))` within R to install all the packages you need to run the code in this note.]
This note was written using [Quarto](https://quarto.org) and compiled with [RStudio](https://posit.co/products/open-source/rstudio/), an integrated development environment (IDE) for working with R.
The source code for this note is available [here](https://raw.githubusercontent.com/iangow/notes/main/import_sirca.qmd).

```{r}
Sys.setenv(RAW_DATA_DIR = "~/Library/CloudStorage/Dropbox/raw_data/")
Sys.setenv(DATA_DIR = "~/Library/CloudStorage/Dropbox/pq_data/")
```

```{r}
#| include: false
options(width = 75,
        tibble.width = 75,
        pillar.print_min = 5)
```

```{r}
#| message: false
library(tidyverse)
library(DBI)
library(arrow)
library(farr)
library(janitor)
```

```{r}
csv_dir <- file.path(Sys.getenv("RAW_DATA_DIR"), "sirca")

si_au_ref_names_csv <- file.path(csv_dir, "si_au_ref_names.csv.gz")
si_au_ref_names <- read_csv(si_au_ref_names_csv)
```

```{r}
si_au_ref_names |>
  select(ends_with("_YMD"))
```

```{r}
si_au_ref_names |>
  distinct() |>
  count(Gcode, SecurityTicker, ListDate, name = "num_rows") |>
  filter(num_rows > 1) |>
  inner_join(si_au_ref_names) |>
  select(Gcode, ListDate, SecurityTicker, GICSIndustry, SIRCAIndustryClassCode)
```

```{r}
si_au_ref_names |>
  select_if(is.character) |>
  select(1:5)
```
```{r}
si_au_ref_names |>
  select_if(is.character) |>
  select(6:7, 10:11) |>
  filter(if_all(everything(), \(x) !is.na(x)))
```
```{r}
si_au_ref_names <-
  read_csv(si_au_ref_names_csv, show_col_types = FALSE) |>
  mutate(across(ends_with("_YMD"), ymd),
         ListDateNew = dmy(ListDate),
         DelistDateNew = dmy(DelistDate))
         
```

```{r}
si_au_ref_names |>
  select(ListDate_YMD, ListDate, ListDateNew) |>
  filter(!is.na(ListDate), ListDateNew != ListDate_YMD)
```

```{r}
si_au_ref_names |>
  select(starts_with("DelistDate")) |>
  filter(!is.na(DelistDate), DelistDateNew != DelistDate_YMD)
```

```{r}
#| include: false
days_since <- 
  si_au_ref_names |>
  filter(!is.na(DelistDate), DelistDateNew != DelistDate_YMD) |>
  select(DelistDate_DaysSince) |>
  pull()
```

```{r}
si_au_ref_names |>
  select(Gcode, starts_with("DelistDate")) |>
  filter(DelistDate_DaysSince == days_since)
```
So it seems that `DelistDate` is to be preferred here, if only in terms of internal consistency.

```{r}
si_au_ref_names |>
  select_if(is.character) |>
  select(8:9) 
```

```{r}
si_au_ref_names |>
  select_if(is.character) |>
  select(12:14) |>
  filter(if_all(everything(), \(x) !is.na(x)))
```

```{r}
si_au_ref_names |>
  select_if(is.character) |>
  select(12:13) |>
  filter(if_all(everything(), \(x) !is.na(x)))
```

```{r}
si_au_ref_names |>
  select(Gcode, SecurityTicker, ListDate, CompanyDelistReasonCode) |>
  mutate(CompanyDelistReasonCode = str_split(CompanyDelistReasonCode, "[;\\.]")) |>
  unnest(CompanyDelistReasonCode) |>
  count(CompanyDelistReasonCode) |>
  arrange(n)
```

```{r}
si_au_ref_names |>
  select_if(is.character) |>
  select(14:15) |>
  filter(if_all(everything(), \(x) !is.na(x)))
```

```{r}
si_au_ref_names |>
  select_if(is.character) |>
  select(16:20) |>
  filter(if_all(everything(), \(x) !is.na(x)))
```

```{r}
#| cache: true
pq_dir <- file.path(Sys.getenv("DATA_DIR"), "sirca")

if (!dir.exists(pq_dir)) dir.create(pq_dir)

si_au_ref_names_pq <- file.path(pq_dir, "si_au_ref_names.parquet")

si_au_ref_names <-
  read_csv(si_au_ref_names_csv,
           show_col_types = FALSE,
           name_repair = str_to_lower) |>
  select(-ends_with("_ymd")) |>
  mutate(across(ends_with("date"), dmy),
         across(c(seniorsecurity, ends_with("dayssince"),
                  recordcount, gicsindustry, sircaindustryclasscode,
                  sircasectorcode),
                as.integer)) |>
  write_parquet(sink = si_au_ref_names_pq) |>
  system_time()
```

```{r}
si_au_ref_names
```

```{r}
si_au_ref_trddays_csv <- file.path(csv_dir, "si_au_ref_trddays.csv.gz")
si_au_ref_trddays_pq <- file.path(pq_dir, "si_au_ref_trddays.parquet")

si_au_ref_trddays <-
  read_csv(si_au_ref_trddays_csv, col_types = "ciDii") |>
  mutate(dateymd = ymd(dateymd))
```

```{r}
si_au_ref_trddays |>
  filter(dateymd != date)

si_au_ref_trddays |>
  mutate(some_date = date - dayssince,
         weekday_calc = wday(date))

si_au_ref_trddays |>
  mutate(
    weekday_calc = wday(date),
    wday = wday(date, label = TRUE)
  ) |>
  count(weekday, weekday_calc, wday)
```

```{r}
si_au_ref_trddays <-
  read_csv(si_au_ref_trddays_csv,
           col_types = "-iDii") |>
  relocate(date) |>
  write_parquet(sink = si_au_ref_trddays_pq) |>
  system_time()
```

```{r}
si_au_retn_mkt_csv <- file.path(csv_dir, "si_au_retn_mkt.csv.gz")
si_au_retn_mkt_pq <- file.path(pq_dir, "si_au_retn_mkt.parquet")

si_au_retn_mkt <-
  read_csv(si_au_retn_mkt_csv,
           col_types = "ciDdddddd",
           locale = locale(date_format = "%d/%m/%Y"),
           name_repair = str_to_lower) |>
  mutate(dateymd = ymd(dateymd))
```

```{r}
si_au_retn_mkt |>
  filter(dateymd != date | is.na(dateymd) | is.na(date))
```

```{r}
si_au_retn_mkt <-
  read_csv(si_au_retn_mkt_csv,
           col_types = "-iDdddddd",
           locale = locale(date_format = "%d/%m/%Y"),
           name_repair = str_to_lower) |>
  relocate(date) |>
  write_parquet(sink = si_au_retn_mkt_pq) |>
  system_time()
```

```{r}
#| cache: true
#| cache-lazy: false
si_au_prc_daily_csv <- file.path(csv_dir, "si_au_prc_daily.csv.gz")
si_au_prc_daily_pq <- file.path(pq_dir, "si_au_prc_daily.parquet")

si_au_prc_daily <-
  read_csv(si_au_prc_daily_csv,
           guess_max = 1e6,
           show_col_types = FALSE) |>
  mutate(dateymd = ymd(dateymd),
         weekday = as.integer(weekday),
         monthend = as.logical(monthend),
         seniorsecurity = as.integer(seniorsecurity)) |>
  system_time()
```

 date = dmy(date), # One difference with dateymd seems to be an error

```{r}
#| cache: true
#| cache-lazy: false
si_au_prc_daily |>
  select(-date) |>
  rename(date = dateymd) |>
  write_parquet(sink = si_au_prc_daily_pq) |>
  system.time()
```

```{r}
export_parquet <- function(df, file) {
 db <- df[["src"]][["con"]]
 df <- dplyr::collapse(df)
 sql <- paste0("COPY (", dbplyr::remote_query(df),
               ") TO '", file, "'")
 DBI::dbExecute(db, sql)
 invisible(df)
}
```

```{r}
#| cache: TRUE
db <- dbConnect(duckdb::duckdb())

si_au_prc_daily <-
  tbl(db, str_c("read_csv('", si_au_prc_daily_csv, "',
                    DateFormat = '%Y%m%d',
                    types = {'dateymd': 'DATE',
                             'dayssince': 'INTEGER',
                             'weekday': 'INTEGER',
                             'monthend': 'BOOLEAN',
                             'seniorsecurity': 'INTEGER'})"),
      name = "si_au_prc_daily") |>
  select(-date) |>
  rename(date = dateymd) |>
  export_parquet(file = si_au_prc_daily_pq) |>
  system_time()

dbDisconnect(db)
```
