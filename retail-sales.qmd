---
title: "Retail sales"
author: 
  - name: Ian D. Gow
    orcid: 0000-0002-6243-8409
    email: iandgow@gmail.com
date: 2025-02-03
number-sections: true
format:
  html:
    default
  pdf: 
    include-in-header:
      text: |
        \usepackage[group-digits = integer, group-separator={,}, group-minimum-digits = 4]{siunitx}
        \usepackage{scrextend}
        \deffootnote{1.6em}{1.6em}{\thefootnotemark.\enskip}
        \addtokomafont{disposition}{\rmfamily}
        \sisetup{output-decimal-marker = {,}}
    colorlinks: true
    geometry:
      - left=2cm
      - right=2cm
    papersize: a4
    mainfont: TeX Gyre Pagella
    mathfont: TeX Gyre Pagella Math
bibliography: papers.bib
---

:::{#tip-pkgs .callout-tip text-align="left"}
The code in this chapter uses the packages listed below.
For instructions on how to set up your computer to use the code found in this book, see @sec-install.
Quarto templates for the exercises below are available on [GitHub](https://github.com/iangow/far_templates/blob/main/README.md).
:::

```{r}
#| warning: false
library(tidyverse)
library(modelsummary)
library(dbplyr)
library(DBI)
```

```{r}
#| eval: false
#| include: false
library(readabs)

Sys.setenv(R_READABS_PATH = "~/Downloads/")

retail_industries <- tribble(
  ~industry, ~ind_level,
  "Supermarket and grocery stores", 2,
  "Liquor retailing", 2,
  "Other specialised food retailing", 2,
  "Food retailing", 1,
  "Furniture, floor coverings, houseware and textile goods retailing", 2,
  "Electrical and electronic goods retailing", 2,
  "Hardware, building and garden supplies retailing", 2,
  "Household goods retailing", 1,
  "Clothing retailing", 2,
  "Footwear and other personal accessory retailing", 2,
  "Clothing, footwear and personal accessory retailing", 1,
  "Department stores", 1,
  "Newspaper and book retailing", 2,
  "Other recreational goods retailing", 2,
  "Pharmaceutical, cosmetic and toiletry goods retailing", 2,
  "Other retailing n.e.c.", 2,
  "Other retailing", 1,
  "Cafes, restaurants and catering services", 2,
  "Takeaway food services", 2,
  "Cafes, restaurants and takeaway food services", 1,
  "Total (Industry)", 0) |>
  mutate(parent_industry = if_else(ind_level == 1, industry, NA)) |>
  fill(parent_industry, .direction = "up") |>
  mutate(parent_industry = if_else(ind_level == 1, "Total (Industry)", 
                                   parent_industry)) 

table <- "TABLE 11. Retail Turnover, State by Industry Subgroup, Original"

abs_data <-
  read_abs("8501.0") |>
  filter(table_title == table) |>
  separate_wider_regex(series,
                       c(label = "^.*", ";\\s+", 
                         state = ".*?", "\\s*;\\s*",
                         industry = ".*?", "\\s*;$")) |>
  mutate(label = str_trim(label)) |>
  select(industry, state, date, value) |>
  rename(sales = value) |>
  arrange(date, industry, state)

retail_sales <-
  abs_data |>
  left_join(retail_industries, join_by(industry)) |>
  write_csv("data/retail_sales.csv") 
```

The data we focus on in this chapter come from the [Australian Bureau of Statistics](https://www.abs.gov.au) (ABS).
The ABS describes itself as "Australia's national statistical agency and an official source of independent, reliable information."
We discuss the source of the data in more detail in @tip-abs.

The data are stored as a **comma-separated value** (CSV) file format in `data/retail_sales.csv` in the repository you downloaded for this course.
There is a good chance that, if Microsoft Excel is installed on your computer, double-clicking on this file on your computer will open it in Excel.
To understand the contents of the file, it's actually better to open it in a text editor, such as Notepad (Windows) or TextEdit (MacOS).
CSV files are a common format for sharing data, as it is a simple format that many software packages can handle.
[Chapter 7](https://r4ds.hadley.nz/data-import.html) of *R for Data Science* discusses CSVs in more detail.

Here we use `read_csv()` from the Tidyverse to load the data into R.

```{r}
retail_sales <- read_csv("data/retail_sales.csv")
```

As can be seen in the output above, `read_csv()` will attempt to infer a number of features of the data.
For example, the first row of the CSV file (`industry,state,date,sales,ind_level,parent_industry`) is assumed to provide the names the columns of the resulting data frame.
Additionally, `read_csv()` will guess the appropriate type for each column.
From the output above, we can see that `industry`, `state`, and `parent_industry` are imported as character columns, that `date` has type date, and that `sales` and `ind_level` have type `dbl` ("double" being the R type for storing real numbers).

The data in `retail_sales` are monthly estimates of turnover [sales in dollars] and volumes for retail businesses, including store and online sales, by industry group and industry subgroup.
According to [the ABS](https://www.abs.gov.au/methodologies/retail-trade-australia-methodology/dec-2024), "estimates of turnover are compiled from the monthly Retail Business Survey.
About 700 'large' businesses are included in the survey every month, while a sample of about 2,700 'smaller' businesses is selected."

# Understanding the industries

According to [the ABS,](https://www.abs.gov.au/methodologies/retail-trade-australia-methodology/jul-2024#defining-retail-trade) the statistics from which `retail_sales` are derived are presented at two levels of detail: *industry group*, "the broadest industry level comprising 6 industry groups", and *industry subgroup*, which is "the most detailed industry level comprising 15 industry subgroups."
In `retail_sales`, industry groups are associated with `ind_level` equal to 1 and industry subgroups are associated with `ind_level` equal to 2.
For each, industry subgroup, the industry group to which it belongs is identified in `parent_industry`.

We can take a peek at the first few rows of data by typing `retail_sales` in the R console:

```{r}
retail_sales
```


We can also get a succinct take on the data using `summary()`:

```{r}
summary(retail_sales)
```
We start by investigating the data in `industry`, `ind_level`, and `parent_industry`.
Below we see that `Total (Industry)` is the parent industry for all industries having `ind_level` equal to one and that `parent_industry` is missing whenever `ind_level` is zero.
Note that only five distinct industries are listed under `parent_industry` when `ind_level` is two.

```{r}
retail_sales |> 
  count(parent_industry, ind_level) |>
  arrange(ind_level)
```

We can identify the missing industry group by using an **anti-join** (`anti_join()`) and `join_by(industry == parent_industry)`.
The output of following query identifies the problem case as "Department stores".

```{r}
retail_sales |>
  filter(ind_level == 1) |>
  anti_join(retail_sales, by = join_by(industry == parent_industry)) |>
  count(industry)
```

Because the function `anti_join(x, y)` returns all rows in `x` that donâ€™t have a match in `y`, it is useful for finding **implicit missing values**.^[TODO: Discuss *implicit missing values* in an earlier section on `left_join()`.]

Additionally, while the ABS website describes the data as "comprising 15 industry subgroups", we see only 14 subgroups in the data:

```{r}
retail_sales |> 
  distinct(industry, ind_level) |> 
  count(ind_level)
```

What explains these discrepancies?
The natural explanation is that *Department stores* is an industry group that has only one subgroup, itself.
In effect, *Department stores* could be considered as having `ind_level` equal to both one and two.

A natural question is whether sales of the subgroups add up to the sales of the industry groups.^[Once we recognize that *Department stores* is its own parent industry, it is trivial that its own sales will "add up" in the sense here, so we don't need to consider that industry for present purposes.]
To answer this question, I first collect data---the sum of sales by state and year---on industry groups directly and store them in `level_1_df`.

```{r}
level_1_df <-
  retail_sales |> 
  mutate(year = year(date)) |>
  filter(ind_level == 1, year < 2024) |>
  group_by(state, year, industry, ind_level) |>
  summarize(no_missing = as.integer(all(!is.na(sales))),
            sales = sum(sales, na.rm = TRUE),
            .groups = "drop")
```

I then collect the same data on industry groups directly by aggregating the applicable industry subgroups and store them in `level_2_df`.

```{r}
level_2_df <-
  retail_sales |> 
  mutate(year = year(date)) |>
  filter(ind_level == 2, year < 2024) |>
  group_by(state, year, parent_industry, ind_level) |>
  summarize(no_missing = as.integer(all(!is.na(sales))),
            sales = sum(sales, na.rm = TRUE),
            .groups = "drop") |>
  rename(industry = parent_industry)
```

Finally, I combine the data from both of these data frames into one data frame using `union_all()` and save the result in `combined_levels`.

```{r}
combined_levels <-
  level_1_df |>
  union_all(level_2_df) |>
  mutate(year = as.character(year),
         ind_level = as.character(ind_level))
```

I will use `datasummary()` from the `modelsummary` package to display summary statistics.
I create `pretty_num()` to format the numbers in the way that I want.

```{r}
pretty_num <- function(x) prettyNum(as.integer(x), format = "f", 
                                    big.mark = ",")
```

I create alternative shorter names for two industries that have names that are too long to fit in the tables I want to display.

```{r}
short_names <-
  tribble(
  ~industry, ~short_ind,
  "Cafes, restaurants and takeaway food services", "Cafes, restaurants, etc",
  "Clothing, footwear and personal accessory retailing", 
    "Clothing, footwear, accessories")
```

In @tbl-reconc, I display the total sales for each industry group calculated in two ways: once by summing up the values for the industry group and again by summing up the values for the subgroups comprised by the group.

```{r}
#| label: tbl-reconc
#| tbl-cap: "Reconciliation of sales by group and sub-groups: Total (State)"
combined_levels |>
  left_join(short_names, by = "industry") |>
  mutate(industry = coalesce(short_ind, industry)) |>
  filter(year >= 2019, 
         state == "Total (State)",
         industry != "Department stores") |>
  datasummary(industry * ind_level ~ sales * sum * year,
              data = _, fmt = pretty_num,
              digits = 1)
```

With any data set it is important to understand the meaning of any explicit missing values.
For the five industry groups (excluding *Department stores* for the reasons discussed above), we have complete information at level 1 for a year if there are 12 months of data for each industry group at level 1.
And we have complete information at level 2 for a year if there are 12 months of data for each sub-group at level 2.
From @tbl-non-missing, we see that larger states have complete data for all five industries at both levels one and two, but that smaller states such as Tasmania and Northern Territory have missing values at both levels.^[Of course, Northern Territory is not a *state*, but a territory.]

```{r}
#| label: tbl-non-missing
#| tbl-cap: "Non-missing values by state and year and industry level"
combined_levels |>
  filter(year >= 2019, 
         industry != "Department stores") |>
  datasummary(state * ind_level ~ no_missing * sum * year,
              data = _, fmt = pretty_num)
```

## Exercises

1. Describe in words what the query above using `anti_join()` is doing.

2. What do functions like `inner_join()` and `union_all()` have in common?
How do they differ?

3. Using the documentation provided for them, explain how `union_all()` and `union()` differ.
Would you expect different results if we had used `union()` instead of `union_all()` in the code above?

4. Suppose we wanted to focus our analysis on industry subgroups, but wanted to retain "Department stores" as part of this.
Write code to create `ind_sub_groups`, a data set comprising data from `retail_sales` that we could use for this purpose.

```{r}
#| label: tbl-reconc-level-2
#| tbl-cap: "Sales by industry subgroup"
#| include: false
combined_levels |>
  mutate(ind_level = if_else(industry == "Department stores", "2", ind_level)) |>
  filter(ind_level == "2",
         year >= 2019) |>
  datasummary(industry * ind_level ~ sales * sum * year,
              data = _, fmt = pretty_num)
```

5. In creating @tbl-reconc, I used `left_join()` and then `coalesce()`.
Why did I need to use `left_join()` rather than `inner_join()`. (*Hint:* Replace `left_join()` with  `inner_join()` and see what happens.)

6. What industry group has missing values at level 2 for Queensland, as seen in @tbl-non-missing?
Which subgroups are affected?

```{r}
#| include: false
combined_levels |>
  filter(year >= 2019, 
         state == "Queensland",
         industry != "Department stores") |>
  datasummary(industry * ind_level ~ sales * sum * year,
              data = _, fmt = pretty_num)
```

4. Produce a version of @tbl-reconc but focused on Queensland instead of all of Australia (`Total (State)`).
Do you see an issue related to the issue flagged in the previous question?

```{r}
#| label: tbl-reconc-qld
#| tbl-cap: "Reconciliation of sales by group and sub-groups: Queensland"
#| include: false
combined_levels |>
  left_join(short_names, by = "industry") |>
  mutate(industry = coalesce(short_ind, industry)) |>
  filter(year >= 2019, 
         state == "Queensland",
         industry != "Department stores") |>
  datasummary(industry * ind_level ~ sales * sum * year,
              data = _, fmt = pretty_num,
              digits = 1)
```

5. Produce a version of @tbl-reconc but focused on Tasmania instead of all of Australia (`Total (State)`).
Do you see an issue related to the issue flagged in the previous question?

```{r}
#| label: tbl-reconc-tas
#| tbl-cap: "Reconciliation of sales by group and sub-groups: Tasmania"
#| include: false
combined_levels |>
  left_join(short_names, by = "industry") |>
  mutate(industry = coalesce(short_ind, industry)) |>
  filter(year >= 2019, 
         state == "Tasmania",
         industry != "Department stores") |>
  datasummary(industry * ind_level ~ sales * sum * year,
              data = _, fmt = pretty_num,
              digits = 1)
```



# Panel data

A very common form of data in business and economics is the **time-series**.
Time-series data involve repeated measurements over time, typically at regular intervals.
Some examples of time-series data sets are:

 - Daily stock prices over time
 - Quarterly measures of an economy's gross domestic product
 - Measures of annual profits for a company
 
An alternative to time-series data is known as **cross-sectional** data, which involves measures at a point of time for multiple entities.
Some examples of cross-sectional data sets are:

 - Closing stock prices for multiple companies on a given day
 - Measures of the gross domestic product for different economies for a given quarter
 - Measures of profits for several companies in a given year
 
Often cross-sectional and time-series data will exist in a single data set.
Such a data set is often known as a **panel data** set.
Some examples of panel data sets are:

 - Daily stock prices for multiple companies over time
 - Quarterly measures of the gross domestic product for different economies over several periods
 - Annual profits for several companies over several year

## Plotting panel data

The `retail_sales` data set is a panel data set with monthly data on retail sales for several "states" and several industries.^[I put "states" in scare quotes because it includes territories and also a series for all states combined (`Total (State)`).]
For a given state and industry, the monthly retail sales series is a time-series.
For an initial exploration of `retail_sales`, I construct `df_group_plot`, a data set focused on a subset of the available dates and the data for all states combined (`state == "Total (State)"`) and the industry groups (`ind_level == 1`).

```{r}
start_date <- as.Date("2010-01-01")
end_date <- as.Date("2024-07-01")

df_group_plot <-
  retail_sales |>
  left_join(short_names, by = "industry") |>
  mutate(industry = coalesce(short_ind, industry)) |>
  filter(state == "Total (State)", ind_level == 1,
         between(date, start_date, end_date))
```

Figures [-@fig-all-ind] and [-@fig-all-ind2] plot sales from `r format(start_date, "%B %Y")` until `r format(end_date, "%B %Y")` by industry group.
While Figures [-@fig-all-ind] and [-@fig-all-ind2] use the same underlying data, they present the information in two different ways.

```{r}
#| label: fig-all-ind
#| fig-cap: Retail sales by industry using `facet_wrap()`
df_group_plot |>
  ggplot(aes(x = date, y = sales / 1e3, colour = industry)) +
  ylab("Sales ($ billion)") +
  xlab("Month") +
  geom_line() +
  facet_wrap(industry ~ ., ncol = 2, scales = "free_y") +
  theme(legend.position = "none")
```

```{r}
#| label: fig-all-ind2
#| fig-cap: Retail sales by industry
df_group_plot |>
  ggplot(aes(x = date, y = sales / 1e3, colour = industry)) +
  ylab("Sales ($ billion)") +
  xlab("Month") +
  geom_line() +
  theme(legend.position = "bottom")
```

### Exercises

1. Identify three patterns in the data observed in Figures [-@fig-all-ind] and [-@fig-all-ind2].
For each pattern, provide a conjecture for what explains the pattern.

2. Describe in words how @fig-all-ind differs from @fig-all-ind2.

3. Describe in words how the code used to create @fig-all-ind was modified to create @fig-all-ind2.

4. In your view, which plot---@fig-all-ind or @fig-all-ind2---best presents the information?
Is one better than the other for identifying the patterns you identified in the previous question?

## Seasonality

One thing you likely noticed about Figures [-@fig-all-ind] and [-@fig-all-ind2] is that retail sales appear to be highly **seasonal**.
Seasonality refers to the tendency of some time-series to exhibit recurring patterns over time.
For example, ice cream sales tend to be higher in summer, while sales of ski boots probably peak in winter months.
To see how we can better understand seasonality, consider @fig-season, which plots sales of *Cafes, restaurants and takeaway food services* for all states combined in a way that allows us to consider each year separately.

```{r}
#| label: fig-season
#| fig-cap: Seasonality
#| fig-height: 5
#| fig-width: 6
retail_sales |>
  filter(industry == "Cafes, restaurants and takeaway food services",
         state == "Total (State)",
         between(date, start_date, end_date)) |>
  mutate(month = month(date, label = TRUE),
         year = year(date)) |>
  ggplot(aes(x = month, y = sales / 1e3, fill = month)) +
  ylab("Sales ($ billion)") +
  xlab("Month") +
  geom_col() +
  facet_wrap(year ~ ., ncol = 3) +
  theme(legend.position = "none") +
  scale_x_discrete(labels = \(x) str_sub(x, 1, 1))
```

### Exercises

1. Looking at @fig-season, which month (if any) generally has the *highest* sales in each year?
Provide a conjecture for the underlying forces causing this month to have the highest sales in most or all years?

2. Looking at @fig-season, which month (if any) generally has the *lowest* sales in each year?
Provide a conjecture for the underlying forces causing this month to have the lowest sales in most or all years?

3. What happens if you omit "`, fill = month`" from the code creating @fig-season?
Does the use of colour add useful information to this plot?

4. What is the line of code "`scale_x_discrete(labels = \(x) str_sub(x, 1, 1))`" doing here?
(*Hint:* Omit this line and compare the plot produced with @fig-season.
Also look at the documentation for `str_sub()`.)

5. Looking again at Figures [-@fig-all-ind] and [-@fig-all-ind2], are all industries equally seasonal?
Which industry do you consider to be the most seasonal?
The least seasonal?
How might you measure the seasonality of each industry using data in that plot?
What complications do you anticipate in measuring seasonality?

:::{#tip-backends .callout-tip text-align="left"}

# Alternative engines

So far, we have done many calculations using `mutate()` and `summarize()`, combined data frames using functions like `inner_join()`, or focused on certain rows or columns using `filter()` or `select()`.
We have generally applied the functions to data in data frames, which we understand to comprise vectors of data stored in the memory (RAM) of our computer.
However, as you work more with data, you are likely to encounter situations where this approach has limitations.

For example, you might have the data stored on disk, but it either would take too long to load or simply cannot fit into RAM.
It turns out that there are packages that provide alternative **engines** that can help us work with this kind data with little change to how we have done things so far:

 - One popular option is `data.table`, a package that provides a "high-performance version of base R's `data.frame` with syntax and feature enhancements for ease of use, convenience and programming speed."
 - Another option is Apache Arrow, "a multi-language toolbox designed for efficient analysis and transport of large datasets."
The `arrow` R package provides a `dplyr` backend allowing users to analyze  larger-than-memory datasets using familiar syntax.
 - Another possibility is that the data you want to work with are stored on a remote computer, such as a database server or a Spark cluster.
If the data or interest are stored in a database, the `DBI` package provides an interface allowing users to connect to most popular databases, execute SQL, and retrieve results.

The `dbplyr` package allows users to create **remote data frames** and execute queries using a familiar interface often identical to that offered by `dplyr`.
Using a remote database server offers a number of potential advantages:

 - Moving processing to where the data are located
 - Moving processing to a more powerful computer
 - Avoiding loading of data into RAM

In this book, in addition to using `dplyr` with data frames, we explore the use of DuckDB as an analytical engine.
DuckDB provides an SQL interface, so working with it is much like working with PostgreSQL or MySQL but, unlike most database server products, DuckDB requires almost no setup and offers significant performance benefits.
While we use DuckDB largely for these performance benefits, we also get the happy side-effect of learning how to work with remote databases.

Another advantage offered by DuckDB is access to more powerful window functions than are offered by `dplyr` itself.
We see these in use in @sec-windows.

:::

## Time windows {#sec-windows}

Many analyses in business and economics involve calculations over **time windows**.
Some examples:

 - Returns on stocks over the days or months after their initial public offerings (IPOs)
 - Comparing sales or profits for the year to date with previous years
 - Smoothing sales over time using moving averages

We will see that working with time windows is greatly facilitated by the use of **window functions** and that the SQL engine offered by DuckDB provides the more-powerful window functions that we will need here.

To create a DuckDB engine, we simply create a connection.

```{r}
db <- dbConnect(duckdb::duckdb())
```

We can then use the function `copy_to()` to move the data from R into the in-memory DuckDB database we have created.^[TODO: Consider alternative approaches to getting data into DuckDB. Probably choose whichever is simplest pedagogically.]

```{r}
retail_sales_db <-
  retail_sales |>
  copy_to(db, df = _, overwrite = TRUE)
```

We can inspect `retail_sales_db` at the R console much as we did with `retail_sales` above.

```{r}
retail_sales_db
```
The output is almost identical to the output shown above when we typed `retail_sales` at the R console.
The two differences are at the top and bottom of the output.
At the top, we now see two lines indicating that the data come from a table inside an in-memory (`:memory`) DuckDB database and thus represent a **remote data frame** rather than a local data frame.^[The terminology "remote" is used even though the data are on the same computer, hence local in a sense. In principle, the data could be on a computer on the other side of the planet (e.g., in a remote PostgreSQL database).]
At the bottom, we no longer see the numeber of rows.
This partly reflects the **lazy** nature of remote data frames: we have to execute a specific query to determine the number of rows.^[TODO: This statement could be tightened up and clarified.]

### Year-to-date (YTD)

Often we will want to compare performance for the current period with that in earlier periods.
If we were in the middle of August 2025, it would not make sense to compare total sales for 2025 with total sales for 2024, as this would be comparing seven months (January through July) with twelve months.
One standard approach is to calculate **year-to-date** performance and compare that with performance for a comparable period from earlier years.

For this exercise, I will focus on industry subgroups of *Cafes, restaurants and takeaway food services* and just two states---Victoria and Western Australia.
I create `cafes_vic_wa_db`, a data frame focused on these observations.

```{r}
cafes_vic_wa_db <-
  retail_sales_db |> 
  filter(str_detect(parent_industry, "^Cafes"),
         state %in% c("Victoria", "Western Australia"))
```

```{r}
#| include: false
cafes_vic_wa <-
  retail_sales |> 
  filter(str_detect(parent_industry, "^Cafes"),
         state %in% c("Victoria", "Western Australia"))
```

The next step is to create `ytd_plot_df`, the data frame that will contain the data we need to plot year-to-date sales.
Here we first calculate `year` and then group by `industry`, `state`, and `year`.
Grouping by `industry` and `state` makes sense as it does not make sense to aggregate data across industries and states in this context.
Grouping additionally by `year` reflects the nature of the YTD calculation we are making: only values for a given year should be consider.

We next use `window_order(date)` so that the following `mutate()` command puts the data in the correct order.
It is helpful to think of the windows that are being created.^[TODO: Put a fleshed-out example of a window here.]

The following line invokes `cumsum(sum)` to calculate the cumulate sales for each `(industry, state, year)` up to the current row (remember that the rows are order by `date`) before invoking `ungroup()` and then `filter()` to focus on the years we want to plot.

The `collect()` command brings the data into R, converting the remote data frame to a local data frame.
The last line converts `year` to a character variable and calculates `month` using the `month()` function.

```{r}
ytd_plot_df <-
  cafes_vic_wa_db |>
  mutate(year = year(date)) |>
  group_by(industry, state, year) |>
  window_order(date) |>
  mutate(sales_ytd = cumsum(sales)) |>
  ungroup() |>
  filter(between(year, 2018, 2021)) |>
  collect() |>
  mutate(year = as.character(year),
         month = month(date, label = TRUE))
```

```{r}
#| include: false
#| eval: false
ytd_plot_df <-
  cafes_vic_wa |>
  mutate(year = year(date)) |>
  group_by(industry, state, year) |>
  arrange(date) |>
  mutate(sales_ytd = cumsum(sales)) |>
  ungroup() |>
  filter(between(year, 2018, 2021)) |>
  collect() |>
  mutate(year = as.character(year),
         month = month(date, label = TRUE))
```

With `ytd_plot_df` in hand, creating @fig-all-ind-ytd is quite straightforward:^[TODO: Should I scale by `1e3` throughout?]

```{r}
#| label: fig-all-ind-ytd
#| fig-cap: Year-to-date sales for cafes
#| fig-height: 6
#| fig-width: 6
ytd_plot_df |>
  ggplot(aes(x = month, y = sales_ytd / 1e3,
             color = year, group = year)) +
  ylab("Sales, year-to-date ($ billion)") +
  xlab("Month") +
  geom_line() +
  facet_wrap(industry ~ state, ncol = 2, scales = "free_y") +
  theme(legend.position = "bottom")
```

#### Exercises

1. What patterns do you observe in @fig-all-ind-ytd?
Can you suggest explanations for these patterns?

1. Is `cafes_vic_wa_db` (created by the code above) a remote data frame or a local data frame?
How can you tell?

2. Does `filter(str_detect(parent_industry, "^Cafes"))` produce the same result as `filter(parent_industry == "Cafes, restaurants and takeaway food services")`?
What benefit is there from using the former option rather than the latter?

3. What happens if you replace the function `window_order()` with function `arrange()`.

3. As an analogue to `cafes_vic_wa_db` (created using `retail_sales_db`), create `cafes_vic_wa` using `retail_sales`.
Use `cafes_vic_wa` to create a version of `ytd_plot_df`.
(*Hint:* You will need to use `arrange()` in place of `window_order()`.)
Does the plot created using this version of `ytd_plot_df` look the same as @fig-all-ind-ytd?

4. Do we need both `color = year` *and* `group = year` in creating @fig-all-ind-ytd?
How can you tell?

5. What happens if we omit `ungroup()` from the code creating `ytd_plot_df`?
Is there any effect on `ytd_plot_df`?
Is there any effect on the appearance of @fig-all-ind-ytd?

6. What is the data type for `month` in `ytd_plot_df`?
(*Hint:* You may find it helpful to type `ytd_plot_df$month` at the R console or to use the function `class()`.)

7. What happens if we move the `mutate()` code creating `year` and `month` in `ytd_plot_df` *before* the `collect()` call?
Does the code still run?
Does the plot look fine?
Can you explain what's going on?
(*Hint:* Go back to the previous question with the new version of `ytd_plot_df`.)

8. In creating `ytd_plot_df`, can we move the application of `as.character()` to the line `mutate(year = year(date))`? 
(That is, can we use `as.character(year(date))` in that line?)
What other code do we need to modify to take this approach?
After making the needed modification, does the plot produced look the same as @fig-all-ind-ytd?
Why did we not need to use the same type for `year` as we did for `month`?
(*Hint:* You may find it helpful to type `ytd_plot_df$year` at the R console or to use the function `class()`.)

### Fiscal year-to-date (YTD)

Above we calculated YTD numbers using *calendar* years.
However, for many purposes, most companies in Australia reckon **fiscal years** from 1 July to 30 June and we might want to plot *fiscal* YTD numbers.

To make this happen, I do two things.
First, I create a function `fiscal_month()` that behaves a lot like `month()`, but with an extra argument that allows me to specify the first month of the fiscal year (e.g., `first_month = 7` would make July the first month of the fiscal year).
For present purposes, you don't need to understand the details of `fiscal_month()`, but note that this actually borrows elements from the original `month()` function itself.

```{r}
fiscal_month <- function(x, first_month = 7, label = TRUE, abbr = TRUE) {
  new_order <- c(first_month:12, 1:(first_month - 1))
  labels <- levels(month(x, label = label, abbr = abbr))
  new_labels <- labels[new_order]
  ordered(month(x), levels = new_order, labels = new_labels)
}
```

The second thing I do is create `fyear` to represent fiscal year based on fiscal years starting in July.
Below is code creating `fytd_plot_df` using `fyear` in place of `year` used in `ytd_plot_df` and using `fiscal_month()` in place of `month()`.


```{r}
fytd_plot_df <-
  cafes_vic_wa_db |>
  mutate(year = year(date),
         fyear = year + as.integer(month(date) >= 7)) |>
  group_by(industry, state, fyear) |>
  window_order(date) |>
  mutate(sales_ytd = cumsum(sales)) |>
  ungroup() |>
  filter(between(fyear, 2018, 2021)) |>
  collect() |>
  mutate(fyear = as.character(fyear),
         month = fiscal_month(date))
```

```{r}
#| include: false
#| eval: false
fytd_plot_df <-
  cafes_vic_wa |>
  mutate(year = year(date),
         fyear = year + as.integer(month(date) >= 7)) |>
  group_by(industry, state, fyear) |>
  arrange(date) |>
  mutate(sales_ytd = cumsum(sales)) |>
  filter(between(fyear, 2018, 2021)) |>
  ungroup() |>
  collect() |>
  mutate(fyear = as.character(fyear),
         month = fiscal_month(date))
```

The following code creates @fig-all-ind-fytd and is essentially identical to that used to create @fig-all-ind-ytd except for changes to reflect use of `fyear` in place of `year`.

```{r}
#| label: fig-all-ind-fytd
#| fig-cap: Fiscal year-to-date sales for cafes
#| fig-height: 6
#| fig-width: 6
fytd_plot_df |>
  ggplot(aes(x = month, y = sales_ytd / 1e3,
             color = fyear, group = fyear)) +
  ylab("Sales, fiscal year-to-date ($ billion)") +
  xlab("Month") +
  geom_line() +
  facet_wrap(industry ~ state, ncol = 2, scales = "free_y") +
  theme(legend.position = "bottom")
```

#### Exercises

1. In words, what is the code creating `fyear` in the creation of `fytd_plot_df` doing?
(*Hint:* You might find it helpful to append `count(fyear, date) |> arrange(date)` to the first two lines of the code creating `fytd_plot_df`.)

2. Why is important to `filter()` using `fyear` rather than `year` (i.e., `between(fyear, 2018, 2021))`)?
(*Hint:* Change the `filter()` to use `year` instead and look at the resulting plot.)

3. What happens if the call to `fiscal_month()` in the creation of `fytd_plot_df` is replaced by a call to `month = month(date, label = TRUE)`?
(*Hint:* Change the code and look at the resulting plot.)

4. What features of the variable `month` in the data frame `fytd_plot_df` ensure that we get the plot we are looking for?

5. Could we use `cafes_vic_wa` in place of `cafes_vic_wa_db` to create `fytd_plot_df`?
What changes do we need to make to the code?
Does the resulting plot look the same as @fig-all-ind-fytd?

### Moving averages

```{r}
df_group_ma_plot <-
  retail_sales_db |>
  left_join(short_names, by = "industry", copy = TRUE) |>
  mutate(industry = coalesce(short_ind, industry)) |>
  group_by(industry, state) |>
  window_order(date) |>
  window_frame(-11, 0) |>
  mutate(sales_ma = cummean(sales),
         count_ma = cumsum(as.integer(!is.na(sales)))) |>
  filter(state == "Total (State)", ind_level == 1,
         between(date, start_date, end_date),
         count_ma >= 12) 
```

```{r}
#| label: fig-all-ind-ma
#| fig-cap: Retail sales (12-month moving average) by industry
df_group_ma_plot |>
  ggplot(aes(x = date, y = sales_ma / 1e3)) +
  ylab("Sales, 12-month moving average ($ billion)") +
  xlab("Month") +
  geom_line() +
  facet_wrap(industry ~ ., ncol = 2, scales = "free_y")
```

### Economic shocks

```{r}
liquor <-
  retail_sales |>
  filter(state %in% c("Victoria", "Western Australia"),
         industry == "Liquor retailing") |>
  filter(between(date, 
                 as.Date("2018-01-01"), 
                 as.Date("2024-08-31"))) |>
  mutate(year = year(date),
         month = month(date, label = TRUE))
```

```{r}
#| label: fig-vic-wa-liq
#| fig-cap: Liquor retailing sales (normalised by 2018 average monthly sales)
#| fig-height: 8
liquor |>
  filter(year == 2018) |>
  group_by(state) |>
  summarize(scale_factor = mean(sales)) |>
  inner_join(liquor, by = "state") |>
  mutate(sales_normalised = sales / scale_factor) |>
  ggplot(aes(x = month, y = sales_normalised, fill = state)) +
  geom_col(position = "dodge") +
  facet_wrap(year ~ ., ncol = 1) +
  theme(legend.position = "bottom") +
  theme(plot.title.position = "plot")
```

:::{#tip-abs .callout-tip text-align="left"}

### Where to find the data

The data used to create `retail_sales` come from the ABS

```{r}
Sys.setenv(R_READABS_PATH = "~/Downloads/")
library(readabs)
```

```{r}
#| cache: true
table <- "TABLE 11. Retail Turnover, State by Industry Subgroup, Original"

abs_data <-
  read_abs("8501.0") |>
  filter(table_title == table) |>
  separate_wider_regex(series,
                       c(label = "^.*", ";\\s+", 
                         state = ".*?", "\\s*;\\s*",
                         industry = ".*?", "\\s*;$")) |>
  mutate(label = str_trim(label)) |>
  select(industry, state, date, value) |>
  rename(sales = value) |>
  arrange(date, industry, state)

abs_data
```

One thing that can be observed in the output above is that there is no indication of which industries are groups and which are subgroups.
Also there is no indication of how the subgroups map to groups.
To handle this, I created the following data frame to map `industry` to `ind_level`.

```{r}
retail_industries <- tribble(
  ~industry, ~ind_level,
  "Supermarket and grocery stores", 2,
  "Liquor retailing", 2,
  "Other specialised food retailing", 2,
  "Food retailing", 1,
  "Furniture, floor coverings, houseware and textile goods retailing", 2,
  "Electrical and electronic goods retailing", 2,
  "Hardware, building and garden supplies retailing", 2,
  "Household goods retailing", 1,
  "Clothing retailing", 2,
  "Footwear and other personal accessory retailing", 2,
  "Clothing, footwear and personal accessory retailing", 1,
  "Department stores", 1,
  "Newspaper and book retailing", 2,
  "Other recreational goods retailing", 2,
  "Pharmaceutical, cosmetic and toiletry goods retailing", 2,
  "Other retailing n.e.c.", 2,
  "Other retailing", 1,
  "Cafes, restaurants and catering services", 2,
  "Takeaway food services", 2,
  "Cafes, restaurants and takeaway food services", 1,
  "Total (Industry)", 0) |>
  mutate(parent_industry = if_else(ind_level == 1, industry, NA)) |>
  fill(parent_industry, .direction = "up") |>
  mutate(parent_industry = if_else(ind_level == 1, "Total (Industry)", 
                                   parent_industry)) 
```

```{r}
retail_sales <-
  abs_data |>
  left_join(retail_industries, join_by(industry)) |>
  write_csv("data/retail_sales.csv") 
```
:::
