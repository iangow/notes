---
title: "SIRCA ASX End of Day (EOD) collection"
author: Ian D. Gow
date: 2024-07-07
date-format: "D MMMM YYYY"
format:
  html:
    colorlinks: true
  pdf: 
    colorlinks: true
    geometry:
      - left=2.5cm
      - right=2.5cm
    papersize: a4
    mainfont: TeX Gyre Pagella
    mathfont: TeX Gyre Pagella Math
bibliography: papers.bib
---

# Overview

SIRCA's ASX EOD (end of day) collection provides daily prices for ASX-listed companies and facilitates reliable measurement of security returns, with all data being retained for delisted companies.
This note, based on SIRCA's own `Guide to ASX End of Day Prices.pdf`, provides an introduction to the SIRCA ASX EOD collection.

The SIRCA ASX EOD collection includes the tables listed in @tbl-asx-eod-keys.
More details can be found in my separate document on importing SIRCA ASX EOF data [here](https://github.com/iangow/notes/blob/main/import_sirca.pdf).

| Table               | Description  | Primary key                            |
|---------------------|--------------|-------------------------:|
| `si_au_ref_names`   | Name and ticker histories for listed companies from January 2000 | `gcode`, `securityticker`, `listdate`  |
| `si_au_prc_daily`   | Complete daily price, volume and value histories | `gcode`, `date`, `seniorsecurity`      |
| `si_au_retn_mkt`    | Daily value- and equal-weighted whole market returns | `date`                                 |
| `si_au_ref_trddays` | Record of ASX trading dates since January 2000  | `date`                                 |

: SIRCA ASX EOD price collections {#tbl-asx-eod-keys}

All company names and ticker codes are recorded in a separate table---`si_au_ref_names`---which links names and tickers through time with a permanent "group code" identifier created by SIRCA named `gcode`.
SIRCA designed `gcode` to allow users to build price and return series for series for a company's shares over time even if its ticker code changes.
The same `gcodes` are used across a number of SIRCA's data sets.

he `si_au_prc_daily` table includes all end-of-day trade prices for the equity securities of all ASX companies starting from January 2000.
This table also includes dividend and franking events; capital returns; adjustments for numerous corporate action events, such as splits, consolidation, bonus issues, renounceable and non-renounceable issues; and total daily traded volume and value; and, the number of issued shares.

Other components of the SIRCA ASX EOD library are `si_au_retn_mkt` which provides value- and equal-weighted all-of-market daily returns, which SIRCA generates from all observable daily company returns.

SIRCA provides `si_au_ref_trdday`, which identifies all ASX trading days since the start of January 2000 and can be used to identify gaps in company price series, from suspensions or thin trading.

Finally SIRCA provides a detailed description of all tables and fields in a data dictionary.

While this note is based on SIRCA's own `Guide to ASX End of Day Prices.pdf`, it goes beyond that guide in a number of respects.
First, I provide detailed instructions on preparing the SIRCA ASX EOD data for use and illustrate analysis using DuckDB and parquet files, a high-performance state-of-the-art approach to data analysis.
The SIRCA guide assumes that the user has access to an SQL database containing the four tables listed in @tbl-asx-eod-keys, but provides no guidance on creating that database.

Second, I provide output---both tables and graphs---for the example queries provided here.
While the SIRCA guide describes observed patterns, it does not provide the output from its queries.

Third, I expand on or refine the queries used in the SIRCA guide.
For example, where the SIRCA guide suggests the use of `dayssince` variables to identify non-trading days, I propose a more robust approach.

The code in this note uses the packages listed below, plus the `duckdb` package.^[Execute `install.packages(c("tidyverse", "DBI", "duckdb", "arrow", "farr", "dbplyr"))` within R to install all the packages you need to run the code in this note. While `duckdb` and `arrow` are not listed below, they are needed to run the download script and to create the database we will use.]
This note was written using [Quarto](https://quarto.org) and compiled with [RStudio](https://posit.co/products/open-source/rstudio/), an integrated development environment (IDE) for working with R.
The source code for this note is available [here](https://raw.githubusercontent.com/iangow/notes/main/sirca_eod.qmd).

```{r}
#| include: false
library(tinytable)

knit_print_alt <- function(x, ...) {
  res <- knitr::knit_print(knitr::kable(x, digits = 3))
  knitr::asis_output(res)
}
```

```{r}
#| message: false
#| warning: false
library(tidyverse)
library(DBI)
library(dbplyr, warn.conflicts = FALSE)
library(farr)
```

# Getting SIRCA ASX EOF data

SIRCA supplies the data we will use as four compressed CSV files.
The original SIRCA note assumes that you have processed the data into an SQL database, but does not provide any details for doing this.
In contrast, I provide the code needed to prepare the data for the analysis below.
I merely assume that you have access to SIRCA and downloaded the raw data from SIRCA along the lines discussed below.^[See [SIRCA's documentation](http://www.sirca.org.au/wp-content/uploads/2023/11/How-to-use-the-Data-Library.pdf) for details on getting the data.]
One you have done that you should be able to execute all the code in this note and thereby produce all the output (tables and graphs) contained herein.

You should download these files and place them *as is* in a single `sirca` directory and you should edit the code below to tell my script where to look for that directory.

In my case, `sirca` is found in `~/Library/CloudStorage/Dropbox/raw_data` and so I execute the following command in RStudio:

```{r}
Sys.setenv(RAW_DATA_DIR = "~/Library/CloudStorage/Dropbox/raw_data")
```

@tbl-csv-files provides details on the contents of the `sirca` subdirectory of `RAW_DATA_DIR` on my computer.

```{r}
#| label: tbl-csv-files
#| tbl-cap: "Data on supplied CSV files from SIRCA"
#| echo: false
#| render: !expr function(x, ...) knit_print_alt(x, ...)
csv_dir <- file.path(Sys.getenv("RAW_DATA_DIR"), "sirca")

file.info(dir(path = csv_dir, full.names = TRUE)) |>
  as_tibble(rownames = "file_name") |>
  mutate(file_name = basename(file_name),
         size = case_when(size > 1e9 ~ str_c(round(size / 1e9, 2), " GB"),
                           size > 1e6 ~ str_c(round(size / 1e6, 2), " MB"),
                           size > 1e3 ~ str_c(round(size / 1e3, 2), " kB"),
                           .default = str_c(size, " B"))) |>
  select(file_name, size) 
```

The script also needs to know where to put the processed data files, which will be in parquet format.
You should edit the following line to refer to a location on *your* computer that you would like to use to store processed SIRCA data.

```{r}
#| eval: false
Sys.setenv(DATA_DIR = "~/Library/CloudStorage/Dropbox/pq_data")
```

```{r}
#| include: false
t <- tempdir()
Sys.setenv(DATA_DIR = t)
```

With the needed packages installed, and `RAW_DATA_DIR` and `DATA_DIR` set, we can run the script to process the SIRCA raw data with the following line.
On my computer, this script takes about 6 seconds to run.
If you wish to learn more about what the script is doing, please see the separate document on importing SIRCA ASX EOF data [here](https://github.com/iangow/notes/blob/main/import_sirca.pdf).

```{r}
#| cache: true
source("https://raw.githubusercontent.com/iangow/notes/main/import_sirca.R", 
       echo = FALSE) |>
  system.time()
```

Details on the resulting parquet files that I have on my computer are provided in @tbl-pq-files.

```{r}
#| include: false
Sys.setenv(DATA_DIR = "~/Library/CloudStorage/Dropbox/pq_data/")
```   

```{r}
#| label: tbl-pq-files
#| tbl-cap: "Data on processed parquet files"
#| echo: false
#| render: !expr function(x, ...) knit_print_alt(x, ...)
pq_dir <- file.path(Sys.getenv("DATA_DIR"), "sirca")

file.info(dir(path = pq_dir, full.names = TRUE)) |>
  as_tibble(rownames = "file_name") |>
  mutate(file_name = basename(file_name),
         size = case_when(size > 1e9 ~ str_c(round(size / 1e9, 2), " GB"),
                           size > 1e6 ~ str_c(round(size / 1e6, 2), " MB"),
                           size > 1e3 ~ str_c(round(size / 1e3, 2), " kB"),
                           .default = str_c(size, " B"))) |>
  select(file_name, size)
```


# Examples

The following examples demonstrate how to do certain analyses using the SIRCA ASX EOD data.
These examples are based on examples provide in the SIRCA guide.
Specifically, I show how one can use the SIRCA ASX EOD collection to do the following analyses:

1. Find a `gcode` from a company's name or ticker code
2. Apply the `cumulativefactor` field to adjust prices for different dividend and corporate action events
3. Generate and plot total shareholder returns
4. Use the `dayssince` column to identify return intervals between consecutive trades
5. Use the `seniorsecurity` column to restrict attention to the residual risk security of each company
6. Recognise and accommodate negative factors and zero volumes
7. Calculate the cumulative factor without dividends
8. Segment market trading activity by trade type and venue

All of the examples here use an in-memory DuckDB database connection.
The following code creates this database connection and reads in three of the four SIRCA ASX EOD tables.
In the cases of `si_au_ref_names`, the code also names that table so that we can refer to it using SQL written "by hand".^[While we access the data in a database throughout, most of the SQL is generated from `tidyverse` (R) code rather than being written by us directly.]

```{r}
db <- dbConnect(duckdb::duckdb())

si_au_ref_names <-
  load_parquet(db, "si_au_ref_names", "sirca") |>
  compute(name = "si_au_ref_names")

si_au_prc_daily <- load_parquet(db, "si_au_prc_daily", "sirca")
si_au_ref_trddays <- load_parquet(db, "si_au_ref_trddays", "sirca")
```

## 1. Finding `gcodes` from company names or ticker codes

One way of searching for a `gcode` is to look up the company name.
For example, we could search for every `gcode` with a company name including `WESTPAC`.
Because we specified `compute(name = "si_au_ref_names")`, we can refer to that table in SQL like the following:

```{sql, tab.cap = NA}
#| connection: db
#| label: tbl-wbc-sql
#| tbl-cap: "Securities matching `WESTPAC`: SQL"
SELECT gcode, securityticker, abbrevcompanyname
FROM si_au_ref_names
WHERE fullcompanyname LIKE '%WESTPAC%'
```

However, the same query could be run using `tidyverse` code:

```{r}
#| label: tbl-wbc-dplyr
#| tbl-cap: "Securities matching `WESTPAC`: Tidyverse"
#| render: !expr function(x, ...) knit_print_alt(x, ...)
si_au_ref_names |>
  filter(str_like(fullcompanyname, '%WESTPAC%')) |>
  select(gcode, securityticker, abbrevcompanyname) |>
  collect()
```

Behind the scenes, the `tidyverse` package is translating our code into SQL:

```{r}
si_au_ref_names |>
  filter(str_like(fullcompanyname, '%WESTPAC%')) |>
  select(gcode, securityticker, abbrevcompanyname) |>
  show_query()
```

Alternatively, one can also search by ticker code, as seen in @tbl-anz-sql using the `securityticker` of `ANZ`.

```{sql, tab.cap = NA}
#| connection: db
#| label: tbl-anz-sql
#| tbl-cap: "Securities with ticker `ANZ`: SQL"
SELECT gcode, securityticker, abbrevcompanyname
FROM si_au_ref_names 
WHERE securityticker = 'ANZ'
```

Again the same query could be run using `tidyverse` code, with results show in @tbl-anz-dplyr.
Because it is so straightforward to run SQL queries using R (`tidyverse`) code, we will just provide R code going forward.^[Users with a background in SQL may find the SQL primer I wrote [here] to be a useful introduction to the `dplyr` package (this is the component of the `tidyverse` package that provides the relevant functions).]
Note that using R code greatly facilitates bringing the data into R for analysis or (as we will do here) data visualization.

```{r}
#| label: tbl-anz-dplyr
#| tbl-cap: "Securities with ticker `ANZ`: Tidyverse"
#| render: !expr function(x, ...) knit_print_alt(x, ...)
si_au_ref_names |>
  filter(securityticker == 'ANZ') |>
  select(gcode, securityticker, abbrevcompanyname) |>
  collect()
```


As another example, suppose one is interested in Arena REIT which has a `companyticker` of `ARF`.
Searching for this ticker code reveals the `gcode` of Arena REIT is `arf2`.
This `gcode` can then be used to search the `si_au_prc_daily` table for information about the securities of Arena REIT.
Results of this search are seen in @tbl-arf.

```{r}
#| label: tbl-arf
#| tbl-cap: "Securities with ticker `ARF`"
#| render: !expr function(x, ...) knit_print_alt(x, ...)
si_au_ref_names |>
  filter(companyticker == 'ARF') |>
  select(gcode, securityticker, abbrevcompanyname, 
         listdate, delistdate) |>
  arrange(listdate) |>
  collect()
```

The previous search reveals that in 2000, the ticker code ARF was then associated with Arrowfield Group Limited.
Arrowfield Group Limited is a different entity to Arena REIT, which was listed in 2013, so the two entities have separate `gcode`s.

A search for `companyticker` of `ARF` also shows that in 2013, the `securityticker` of Arena REIT briefly changed from `ARF` to `ARFDA`, and then back to `ARF`, due to conversions to and from deferred units.
If the holders of units in Arena REIT in 2013 participated in these conversions, then it makes sense to consider them as a single security, which is possible if we accumulate returns using the `gcode` of `arf2`, which remains unchanged throughout this period.

## 2. Adjusting for the effects of corporate actions

@fig-bhp-unadj shows a large drop in the closing price of BHP in late June 2001.

```{r}
#| label: fig-bhp-unadj
#| fig-cap: BHP stock price during 2001
si_au_prc_daily |>
  filter(gcode == 'bhp1',
         between(date, '2001-01-01', '2001-12-31')) |>
  ggplot(aes(x = date, y = close)) +
  geom_line()
```

Examining the `coraxdescription` column, it seems likely that the change is due to a `1:0.94` bonus issue.

```{r}
#| label: tbl-bhp-corax
#| tbl-cap: "Corporate action events for BHP in 2001"
#| render: !expr function(x, ...) knit_print_alt(x, ...)
si_au_prc_daily |>
  filter(gcode == 'bhp1',
         between(date, '2001-01-01', '2001-12-31')) |>
  filter(!is.na(coraxdescription)) |>
  select(gcode, date, close, coraxdescription) |>
  collect()
```

The `coraxdescription` column provides details of corporate action (CORAX) events, when available.
The `numberofdilutionevents` field will always show a value greater than 0 when a dilution event (CORAX or dividend) has occurred and `numberofcoraxevents > 0`  indicates CORAX events, even if `coraxdescription` is not available.
Likewise, `numberofdividendevents > 0` can be used to find all dividend events, even when data are not available in other descriptive fields .

```{r}
#| label: tbl-bhp-factor
#| tbl-cap: "Values of `factor` for BHP around 27 June 2001"
#| render: !expr function(x, ...) knit_print_alt(x, ...)
si_au_prc_daily |>
  filter(gcode == 'bhp1', 
          between(date, '2001-06-27', '2001-07-02')) |>
  select(gcode, date, close, factor, numberofcoraxevents) |>
  collect()
```

The `cumulativefactor` column can be used to adjust the closing price for the effects of corporate actions, such stock splits or entitlement offers, and dividends.
Simply multiplying the `close` column by the `cumulativefactor` column will produce the adjusted price.

```{r}
#| label: fig-bhp-adj
#| fig-cap: BHP adjusted stock price during 2001
 si_au_prc_daily |>
  filter(gcode == 'bhp1',
         between(date, '2001-01-01', '2001-12-31')) |>
  mutate(adjustedprice = close * cumulativefactor) |>
  ggplot(aes(x = date, y = adjustedprice)) +
  geom_line()
```

In this case the new `adjustedprice` series is everywhere lower than `close` because `cumulativefactor` is affected by all CORAX events to the end of each series of `close` prices.
This is so the resulting `adjustedprice` series is consistent over its entire history and can reliably measure returns between any two trading dates for `bhp1`.


```{r}
#| label: tbl-bhp-factor-calc
#| tbl-cap: "Calculated values of `factor` for BHP around 27 June 2001"
#| render: !expr function(x, ...) knit_print_alt(x, ...)
si_au_prc_daily |>
  group_by(gcode, seniorsecurity) |>
  window_order(desc(date)) |>
  mutate(cum_factor_calc = exp(cumsum(log(abs(factor))))) |>
  mutate(cum_factor_calc = lag(cum_factor_calc) * sign(lag(factor))) |>
  window_order() |>
  ungroup() |>
  filter(gcode == 'bhp1', 
          between(date, '2001-06-27', '2001-07-02')) |>
  select(gcode, date, close, factor, cumulativefactor, cum_factor_calc) |>
  arrange(date) |>
  collect()
```


Exactly the same process for `cumulativefactor` applies for dividends as well as corporate actions.
`AAA` (`gcode`: `aaa2`) is an exchange-traded fund that deposits money in accounts with Australian banks and  pays regular dividends 
The effect of its dividends on its closing price can be observed from a graph.

```{r}
#| label: fig-aaa2
#| fig-cap: "Adjusted and unadjusted closing prices for `AAA`"
si_au_prc_daily |>
  filter(gcode == 'aaa2', between(date, '2017-01-01', '2018-12-31')) |>
  mutate(adjustedprice = close * cumulativefactor) |>
  select(date, close, adjustedprice) |>
  pivot_longer(-date, names_to = "variable", values_to = "price") |>
  ggplot(aes(x = date, y = price, color = variable)) +
  geom_line()
```

## 3. Plotting a distribution of price relatives for a security

The following function can calculate the price relative, or total shareholder return, for a security.
Note that it requires the price to be adjusted for corporate actions and dividends, and to be ordered by `date`.

```{r}
#| label: fig-cba1
#| fig-cap: "Distribution of daily returns for Commonwealth Bank"
si_au_prc_daily |>
  filter(gcode == 'cba1') |>
  mutate(adjustedprice = close * cumulativefactor) |>
  group_by(gcode) |>
  window_order(date) |>
  mutate(prel = adjustedprice / lag(adjustedprice)) |>
  ungroup() |>
  window_order() |>
  filter(!is.na(prel)) |>
  ggplot(aes(x = prel)) +
  geom_histogram(binwidth = 0.005)
```

## 4. `dayssince` column

It is important to note that price relatives calculated in the previous section may not always be over consecutive trading days.
Although CBA is a stock that is consistently traded, a less-liquid security may show large gaps in trading activity, leading to price relatives that span longer time periods.
@fig-cba1-days shows the distribution of `days_elapsed`, the number of elapsed days between trading dates calculated using using the `datesince` column, for Commonwealth Bank.
As a measure of the liquidity of a security, `days_elapsed` is problematic because it does not distinguish between days on which the market is open and those on which it is closed.

```{r}
#| label: fig-cba1-days
#| fig-cap: "Distribution of days between trading dates for Commonwealth Bank"
si_au_prc_daily |>
  filter(gcode == 'cba1') |>
  group_by(gcode) |>
  window_order(date) |>
  mutate(days_elapsed = dayssince - lag(dayssince)) |>
  count(days_elapsed, sort = TRUE) |>
  filter(!is.na(days_elapsed)) |>
  ggplot(aes(x = days_elapsed, y = n)) +
  geom_col() +
  scale_x_continuous(breaks = 1:5)
```
We can improve on this measure using data from `si_au_ref_trddays`, a sample of which is shown in @tbl-trddays.

```{r}
#| label: tbl-trddays
#| tbl-cap: "Sample rows from `si_au_ref_trddays`"
#| render: !expr function(x, ...) knit_print_alt(x, ...)
si_au_ref_trddays |> collect(n = 10)
```

Using an approach described in more detail [here](https://iangow.github.io/far_book/beaver68.html#a-re-evaluation-of-beaver1968vf), in place of `dayssince`, we can create a variable `td` to represent the "trading date" for each date on `si_au_ref_trddays` where `td` equals `1` on the first trading date, `2` the second trading date, and so on.

```{r}
trading_days <- 
  si_au_ref_trddays |>
  window_order(date) |>
  mutate(td = row_number()) |>
  distinct(date, td) |>
  arrange(date) |>
  compute()
```

With `trading_days` in hand, we can calculate `tdays_elapsed` as the number of trading dates between the current date and the previous date on `si_au_prc_daily` for each security and date. 

```{r}
tdays_elapsed_df <-
  si_au_prc_daily |>
  inner_join(trading_days, by = "date") |>
  group_by(gcode, seniorsecurity) |>
  window_order(date) |>
  mutate(tdays_elapsed = td - lag(td),
         lag_date = lag(date)) |>
  select(gcode, seniorsecurity, date, lag_date, tdays_elapsed) |>
  ungroup()
```

@tbl-tdays provides data on our improved measure of trading days between trading dates for both Commonwealth Bank (`cba1`) and a less liquid security (`1st1`).
In @tbl-tdays, it can be seen that there are very few cases in which the trading days between dates is more than one for `cba1`, but quite a few such cases for `1st1`.

```{r}
#| label: tbl-tdays
#| tbl-cap: "Trading days between trading dates: `cba1` and `1st1`"
#| render: !expr function(x, ...) knit_print_alt(x, ...)
tdays_elapsed_df |>
  filter(gcode %in% c('cba1', '1st1'),
         !is.na(tdays_elapsed)) |>
  count(gcode, tdays_elapsed) |>
  pivot_wider(names_from = "gcode", values_from = "n", values_fill = 0) |>
  arrange(tdays_elapsed) |>
  collect()
```

@tbl-cba1-gaps provides additional information on the apparent gaps in trading for Commonwealth Bank.
We can use these data to investigate the cause of these gaps.
Looking at the longest gap, it turns out there was a trading halt placed on [12 August 2015](https://announcements.asx.com.au/asxpdf/20150812/pdf/430fwrn8xk90lg.pdf).

```{r}
#| label: tbl-cba1-gaps
#| tbl-cap: "Gaps in trading for Commonwealth Bank"
#| render: !expr function(x, ...) knit_print_alt(x, ...)
tdays_elapsed_df |>
  filter(gcode == 'cba1', tdays_elapsed > 1) |>
  collect()
```

A natural question might be whether there are dates on `si_au_prc_daily` not found on `si_au_ref_trddays`.
@tbl-non-trddays shows that there are, but a small number of securities (in most cases, just one) have data on `si_au_prc_daily` on those days.
I leave it as an exercise for the reader to understand what's going on in these cases.

```{r}
#| label: tbl-non-trddays
#| tbl-cap: "Observations on `si_au_prc_daily` on non-trading days"
#| render: !expr function(x, ...) knit_print_alt(x, ...)
si_au_prc_daily |>
  distinct(date) |>
  anti_join(si_au_ref_trddays, by = "date") |>
  inner_join(si_au_prc_daily, by = "date") |>
  count(date) |>
  mutate(wday = wday(date, label = TRUE)) |>
  arrange(desc(n)) |>
  collect(n = 10)
```

## 5. `seniorsecurity` column

At times, some `gcodes` have multiple securities trading simultaneously.
This is because these companies have more than one class of security and a junior security class has been included in `si_au_prc_daily`.
Over time, other junior security classes may be included too, which means it is important to keep the different price series consistent.
The `seniorsecurity` column is included so you can focus on just the senior security series for any company.
In the next example, two classes of security are shown to be simultaneously trading for Telstra Corporation Ltd, whose `gcode` is `tls1`.
These are evident from the different `securityticker` values: `TLS` and `TLSCA`.
Notice the `seniorsecurity` field correctly separates these two series.

```{r}
#| label: tbl-telstra
#| tbl-cap: "Sample of `securityticker` values for Telstra (`tls1`)"
#| render: !expr function(x, ...) knit_print_alt(x, ...)
si_au_prc_daily |>
  filter(gcode == 'tls1', between(date, "2008-05-01", "2008-05-07")) |>
  select(gcode, date, securityticker, seniorsecurity) |>
  arrange(date) |>
  collect()
```

## 6. Negative `factor` values and zero `volumeonmkt` values

The `factor` field may show a value of `-1` in some cases.
When there is either no observed trade price before an event or no price after the event, a factor of `-1` is assigned to the event.
This can occur both in the beginning and the end of the lifetime of the security.
Relatively few observations have negative `factor` values.

```{r}
#| label: tbl-num-neg-factors
#| tbl-cap: "Number of observations by negative factors"
#| render: !expr function(x, ...) knit_print_alt(collect(x), ...)
si_au_prc_daily |>
  mutate(neg_factor = factor < 0) |>
  count(neg_factor)
```

```{r}
#| label: tbl-neg-cum-factors
#| tbl-cap: "Values of `cumulativefactor` when `factor` is negative"
#| render: !expr function(x, ...) knit_print_alt(collect(x), ...)
si_au_prc_daily |>
  filter(factor == -1) |>
  count(factor, cumulativefactor)
```

But it turns out that when `factor == -1` and `cumulativefactor != -1`, there is no value of `close`.
So there is no risk of calculating an adjusted close price that has no trades behind it.

```{r}
si_au_prc_daily |>
  filter(factor == -1, cumulativefactor != -1, !is.na(close)) |>
  select(gcode, date, seniorsecurity, factor, cumulativefactor) |>
  count() |>
  pull()
```

```{r}
#| label: tbl-strange-factor
#| tbl-cap: "Difficult-to-explain `factor` values"
#| render: !expr function(x, ...) knit_print_alt(collect(x), ...)
si_au_prc_daily |>
  filter(gcode == "gcm2", seniorsecurity == 1,
         factor != 1) |>
  select(gcode, date, factor, cumulativefactor)
```

The following example shows dividends between `2000-03-06` and `2001-09-28` without any trading.
As no trading was observed prior to these dividend events, the `factor` and `dividendfactor` fields contain a value of `-1`.
This makes sense, as one could not meaningfully push the sequence of stock returns back to dates before `2002-03-15`, as there are no traded prices.
There is a non-negative factor value for `2002-03-18`, presumably because there are prices reported after `2002-03-18`.

```{r}
#| label: tbl-npx1-factor
#| tbl-cap: "Negative `factor` values and `npx1`"
#| render: !expr function(x, ...) knit_print_alt(x, ...)
si_au_prc_daily |> 
  filter(gcode == 'npx1', date <= '2002-09-23', seniorsecurity == 1) |>
  select(gcode, date, close, dividend, factor, dividendfactor, volumeonmkt) |>
  collect()
```

The following example shows a dividend on `2004-07-05`.
However, no price was observed after the event, and hence the `factor` and `dividendfactor` fields contain a value of `-1`.
Note that there is a price in the `close` field on `2004-07-05` but it was not observed that day, after the dividend event.
This is evident from the 0 value for `VolumeOnMkt`, and confirmed by `NA` or `0` values for `open`, `high`, `low`.
This price is simply the previous observed trade price carried forward.
This makes sense, as one could not meaningfully push the sequence of stock returns forward to dates after `2004-07-02`, as there are no traded prices.

```{r}
#| render: !expr function(x, ...) knit_print_alt(x, ...)
si_au_prc_daily |> 
 filter(gcode == 'wsf1', date >= '2004-07-01', seniorsecurity == 1) |>
  select(gcode, date, close, dividend, factor, dividendfactor, volumeonmkt) |>
  collect()
```

## 7. Calculating cumulative factor without including dividends

The provided `cumulativefactor` field is calculated by cumulating the `factor` column.
This adjustment includes both corporate actions and dividends and is included in the table for convenience.
For users wishing to calculate an adjustment without including dividends, the following example is provided for reference.
It uses the `adjustmentfactor` field, which provides dilution factors for just the CORAX events (when followed at some time by a valid `close` price).
Please note the following code converts all factors of `-1` into factors of `1`.
This is appropriate if the unobserved price does not change following the event leading to the factor of `-1`.
The function may not be appropriate for your particular application if that assumed pricing behaviour is invalid.

```{r}
#| render: !expr function(x, ...) knit_print_alt(collect(x), ...)
si_au_prc_daily |>
  filter(adjustmentfactor < 0) |>
  count(adjustmentfactor)
```

```{r}
#| render: !expr function(x, ...) knit_print_alt(x, ...)
si_au_prc_daily |>
  group_by(gcode, seniorsecurity) |>
  window_order(desc(date)) |>
  mutate(cumulativefactor2 = exp(cumsum(log(abs(factor))))) |>
  mutate(cumulativefactor2 = lag(cumulativefactor2) * sign(lag(factor))) |>
  window_order() |>
  ungroup() |>
  filter(gcode == "par1", between(date, "2018-12-03", "2019-02-18")) |> # par1
  select(gcode, date, adjustmentfactor, cumulativefactor, close, cumulativefactor2) |>
  arrange(desc(date))
```

Use the `adjustmentfactor` field, which does not account for dividends.
Visualise the new adjustment and compare to the adjustment from the example in part 1 Note that the `CorpAdjustedPrice`, which is calculated without including dividends, looks identical to the `close` price as no corporate actions have occurred within this time frame.

The following shows the effect that dividends can have on the adjusted price series.
The `AdjustedPrice` series incorporates both CORAX factors and dividend factors, whereas the `CorpAdjustedPrice` series incorporates only CORAX adjustments and ignores dividends.
The CORAX-only price series shows a visible fall at the time when the dividend occurs as the value of the dividend is not accounted for.

```{r}
adj_rets <-
  si_au_prc_daily |>
  group_by(gcode, seniorsecurity) |>
  window_order(desc(date)) |>
  mutate(corporatefactor = exp(cumsum(log(abs(adjustmentfactor))))) |>
  mutate(corporatefactor = lag(corporatefactor) *
           sign(lag(adjustmentfactor))) |>
  mutate(CorpAdjustedPrice = corporatefactor * close,
         AdjustedPrice = close * cumulativefactor) |>
  window_order() |>
  ungroup()
```

```{r}
anz_cum <-
  adj_rets |>
  filter(gcode == "anz1") |>
  select(gcode, date, CorpAdjustedPrice, AdjustedPrice, close) |>
  compute()
```
  
```{r}
anz_cum |>
  pivot_longer(cols = ends_with("Price"), 
               names_to = "series", values_to = "price") |>
  filter(!is.na(price)) |>
  ggplot(aes(x = date, y = price, color = series)) +
  geom_line()
```

```{r}
anz_cum |>
  group_by(gcode) |>
  window_order(date) |>
  mutate(across(c(AdjustedPrice, CorpAdjustedPrice),
                \(x) coalesce(x / lag(x), 1)),
         across(c(AdjustedPrice, CorpAdjustedPrice),
                \(x) exp(cumsum(log(x))))) |>
  window_order() |>
  pivot_longer(cols = ends_with("Price"), 
               names_to = "series", values_to = "price") |>
  filter(!is.na(price)) |>
  ggplot(aes(x = date, y = price, color = series)) +
  geom_line()
```

```{r}
#| render: !expr function(x, ...) knit_print_alt(x, ...)
si_au_prc_daily |> 
 filter(gcode == 'dmg1', 
        between(date, "2012-07-01", "2012-07-13"), 
        seniorsecurity == 1) |>
  select(gcode, date, close, dividend, factor, dividendfactor, volumeonmkt) |>
  collect()
```

Note the large difference between the different forms of adjusted price.
As revealed by the command above, this is due to the dividend of 0.4497 on `2012-07-09`, which precedes a fall in `close` price from 0.575 to 0.019.
Adjusting only for CORAX events can clearly lead to significantly different measures of share price performance when dividends are also present.
CORAX adjustments may also be used to standardise earnings information through time.

## 8. Segmentation by trade type

The `si_au_prc_daily` table also contains information on the count, volume, and value of trades by various  categories.
This section provides examples of aggregating trading activity by different trade types:

1.  Trading activity across the whole market
2.  Segmentation by on vs off-market trades
3.  Proportion of on-market non-crossing trades that are carried out through ASX Centre Point
4.  Comparison of lit-pool and dark-pool trading

A graph from the following command shows the value of trading activity across the year plotted against time.
Trading activity can vary significantly from month to month.

```{r}
si_au_prc_daily |>
  filter(between(date, '2016-01-01', '2019-12-31')) |>
  group_by(date) |>
  summarize(ValueWholeMkt = sum(valueonmkt + valueoffmkt, na.rm = TRUE)) |>
  ggplot(aes(x = date, y = ValueWholeMkt)) +
  geom_line()
```

```{r}
si_au_prc_daily |>
  filter(between(date, '2016-01-01', '2019-12-31')) |>
  group_by(date) |>
  summarize(across(c(valueonmkt, valueoffmkt), \(x) sum(x, na.rm = TRUE))) |>
  pivot_longer(-date, names_to = "location", values_to = "value") |>
  ggplot(aes(x = date, y = value, color = location)) +
  geom_line()
```

As mentioned above, it is possible to segment the market by the visibility of trades.
In the lit market, the order book is public and all orders (bid and offer)  are visible to all participants.
Im contrast, in the dark market, the order book is not visible until trades are executed.
The dark pool consists of both on-market and off-market crossing trades, as well as any Centre Point trades.
This following section shows the distribution of activity across the lit and dark markets over time.
Note: As our Centre Point trade measures include crossing trades, Centre Point crossing trade volumes need to be subtracted to avoid double-counting these trades in the calculation of the dark pool trading.

```{r}
si_au_prc_daily |>
  filter(between(date, '2017-01-01', '2019-12-31'),
         volumeonmkt > 0) |>
  group_by(date) |>
  summarize(Dark = sum(volumeoffmktcross + volumeonmktcross +
                         volumecentrept - volumecentreptcross),
            Lit = sum(volumeonmkt + volumeoffmkt - 
                        (volumeoffmktcross + volumeonmktcross +
                           volumecentrept - volumecentreptcross))) |>
  pivot_longer(cols = -date, names_to = "market", values_to = "volume") |>
  ggplot(aes(x = date, y = volume, color = market)) +
  geom_line()
```

The ASX Centre Point matching system provides a market for dark pool liquidity.
As such, Centre Point trades are a subset of on-market trades.
More information on ASX Centre Point can be found on the [ASX website](https://www.asx.com.au/markets/trade-our-cash-market/asx-equities-trading/asx-centre-point.html).
The composition of each market segment is displayed at the bottom of the `si_au_prc_daily` tab in our data dictionary for this service.
The following example shows the average proportion of on-market non-crossing trades that are directed through ASX Centre Point over a period of time.

```{r}
si_au_prc_daily |>
  filter(valueonmkt > 0, valuecentrept > 0) |>
  mutate(month = floor_date(date, "month")) |>
  group_by(month) |>
  summarize(AvgPropCentrePtNonCross = 
              mean((valuecentrept - valuecentreptcross) /
                     (valueonmkt - valueonmktcross))) |>
  ggplot(aes(x = month, y = AvgPropCentrePtNonCross)) +
  geom_line()
```

It is a simple matter to focus on particular market segments.
For example, the previous query can be targeted on companies whose market capitalisation is less than \$50 million.

```{r}
si_au_prc_daily |>
  filter((close * shares) < 50000000,
         valueonmkt > 0, valuecentrept > 0) |>
  mutate(month = floor_date(date, "month")) |>
  group_by(month) |>
  summarize(AvgPropCentrePtNonCross = 
              mean((valuecentrept - valuecentreptcross) /
                     (valueonmkt - valueonmktcross))) |>
  ggplot(aes(x = month, y = AvgPropCentrePtNonCross)) +
  geom_line()
```

```{r}
si_au_prc_daily |>
  filter(valueonmkt > 0, valuecentrept > 0) |>
  mutate(Dark = volumeoffmktcross + volumeonmktcross +
                         volumecentrept - volumecentreptcross,
         CentrePt = volumecentrept - volumecentreptcross) |>
  mutate(month = floor_date(date, "month")) |>
  group_by(month) |>
  summarize(AvgPropCentrePtDark = mean(CentrePt / Dark)) |>
  ggplot(aes(x = month, y = AvgPropCentrePtDark)) +
  geom_line()
```

```{r}
dbDisconnect(db)
```
